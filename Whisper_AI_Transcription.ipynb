{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install ffmpeg-python\n",
        "!pip install tempfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uuSIJjZapzv",
        "outputId": "8ad5f56b-c9e4-4b42-c3d3-ad182016910c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-xfxy9fzh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-xfxy9fzh\n",
            "  Resolved https://github.com/openai/whisper.git to commit 25639fc17ddc013d56c594bfbf7644f2185fad84\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper==20240930)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper==20240930)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=ba6ed84a8b18dd0ce587a03d90db51aa13aaecbe38173ed612b7d1054a2f6676\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0qenm32l/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tempfile (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tempfile\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import whisper\n",
        "import os\n",
        "import urllib"
      ],
      "metadata": {
        "id": "aW4TrQBQa_S8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary directory to store the downloaded MP4 file\n",
        "temp_dir = tempfile.TemporaryDirectory()\n",
        "\n",
        "# longer video from the internet archives (deposition, ~1hr)\n",
        "#url = \"https://ia801504.us.archive.org/20/items/opioids_fgxh0257/fgxh0257-0003.mp4\"\n",
        "\n",
        "# shorter (4 min) video from industry archives\n",
        "url = \"https://archive.org/download/tobacco_wbr62a00/tobacco_wbr62a00.mp4\"\n",
        "\n",
        "source_file_name = url.split('/')[-1]\n",
        "print(\"downloading file\")\n",
        "urllib.request.urlretrieve(url, source_file_name)\n",
        "\n",
        "source_file = os.path.join(source_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEmVQ6VJbGxA",
        "outputId": "662bff24-56e0-43b5-bcca-2ddca3ec9ceb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_model = whisper.load_model(\"tiny\")\n",
        "#base_model = whisper.load_model(\"base\")\n",
        "#small_model = whisper.load_model(\"small\")\n",
        "#medium_model = whisper.load_model(\"medium\")\n",
        "#large_model = whisper.load_model(\"large\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usc1K8WkbI0B",
        "outputId": "c622b336-e9a6-4cce-f2e9-d008f68a5a89"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 72.1M/72.1M [00:01<00:00, 51.9MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tiny_result = tiny_model.transcribe(source_file)\n",
        "tiny_text = tiny_result['text']\n",
        "print(tiny_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYTkWInNbQks",
        "outputId": "5cf94509-8cef-4d05-c9c4-7913f50860ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Think smoking makes you look cool. No way. What are you looking at? Hey, Krissie! What? Think smoking makes you look cool. No way. What? Keep on my things, I can't know. I'm jumping now. Always telling us what to do. Or not to do. But we know what's going on. We listen. Like smoking. We don't know the reason it's not to. But out here comes up. That's when we meet the real decision. That's for us. It's not for the smoke. And that's not even the hardest decision out there, my baby. I mean, you know. So how about a little kind of purchase? My parents. They always think I'm not listening. I hear them. Wait a minute. You know, every day you have to do something. You have to deal with stuff on your own. So you want to know why I decided not to smoke. Which reason would you like? I don't need to smoke to prove myself. My coolness is not on trial here. I don't smoke because sometimes it's what you don't do. That makes you who you are. These are the kids that I've seen. They're all cool in different ways. Or a lot of like too. Because you know, we all deal with the same stuff. Same decisions. Like smoking. Forget it. We all came up with the same answer. Not for us. We don't have to smoke to be different. Being ourselves is enough. Hey guys. Now you ask you a couple questions? I've never tried cigarettes. So what? I don't know. I just never wanted to know. Really? Yeah. Someone fresh harder to whatever somebody have a pack at the school. You know, they smoke you know what I mean. And do you think they try to get other people doing it? Yeah. Yeah. But that's dumb though. You see what I'm saying? I mean, the reason I just don't know. They're not dumb, but. That's the reason it's the only thing. I'm not stupid. You're not stupid. Take it easy. Hey you. Me? Yeah. Did you ever try cigarettes? I was 14. Any reason? Because I was trying to be closer to something. Really? Well yeah. So you tried it because other people were doing it? Yeah, I guess. And why don't you do it anymore? A lot of reasons. Just didn't like it, you know? I don't need a smoke to like fit in. Hold up. We finished? Yeah.\n",
            "CPU times: user 6.49 s, sys: 383 ms, total: 6.87 s\n",
            "Wall time: 9.75 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU times: user 27.4 s, sys: 560 ms, total: 28 s\n",
        "#Wall time: 32 s"
      ],
      "metadata": {
        "id": "u7UMKUXgbnF5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tiny_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bADXnT68bTfo",
        "outputId": "56b7f599-1ff1-4c8f-aaa6-e14a8b9400d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Think smoking makes you look cool. No way. What are you looking at? Hey, Krissie! What? Think smoking makes you look cool. No way. What? Keep on my things, I can't know. I'm jumping now. Always telling us what to do. Or not to do. But we know what's going on. We listen. Like smoking. We don't know the reason it's not to. But out here comes up. That's when we meet the real decision. That's for us. It's not for the smoke. And that's not even the hardest decision out there, my baby. I mean, you know. So how about a little kind of purchase? My parents. They always think I'm not listening. I hear them. Wait a minute. You know, every day you have to do something. You have to deal with stuff on your own. So you want to know why I decided not to smoke. Which reason would you like? I don't need to smoke to prove myself. My coolness is not on trial here. I don't smoke because sometimes it's what you don't do. That makes you who you are. These are the kids that I've seen. They're all cool in different ways. Or a lot of like too. Because you know, we all deal with the same stuff. Same decisions. Like smoking. Forget it. We all came up with the same answer. Not for us. We don't have to smoke to be different. Being ourselves is enough. Hey guys. Now you ask you a couple questions? I've never tried cigarettes. So what? I don't know. I just never wanted to know. Really? Yeah. Someone fresh harder to whatever somebody have a pack at the school. You know, they smoke you know what I mean. And do you think they try to get other people doing it? Yeah. Yeah. But that's dumb though. You see what I'm saying? I mean, the reason I just don't know. They're not dumb, but. That's just too good reason it's the only thing. After. After. Second easy. Hey you. Me? Yeah. Did you ever try cigarettes? I was 14. Any reason? Because I was trying to be closer something. Really? Well yeah. So you tried it because other people were doing it? Yeah, I guess. And why don't you do it anymore? A lot of reasons. Just didn't like it you know? And I need a smoke to like fit in. Hold up. We finished?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdOXS5_Mbe4d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}